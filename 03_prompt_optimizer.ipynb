{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo de código de optimizador de prompts\n",
    "Este código muestra cómo optimizar un prompt para un modelo de lenguaje GPT-3.5. El codigo esta basado en el paper [Large Language Models as Optimizers. Yang et al. (2023).](https://doi.org/10.48550/arXiv.2309.03409)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.- Setup inicial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1- Instalar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install openai\n",
    "#! pip install tenacity\n",
    "#! pip install openai[datalib]\n",
    "#! pip install python-dotenv\n",
    "#! pip install tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.- Cargar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from tabulate import tabulate\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.- Variables de entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load secrets and config from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI API\n",
    "openai.api_type = os.getenv(\"OPENAI_API_TYPE\")\n",
    "openai.api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "openai.api_version = os.getenv(\"OPENAI_API_VERSION\")\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "embedding_model = os.getenv(\"OPENAI_EMBEDDING_MODEL\")\n",
    "print(\"OpenAI API key: {}\".format(openai.api_key[:5] + '...' + openai.api_key[-5:]))\n",
    "print(\"OpenAI API base: {}\".format(openai.api_base))\n",
    "print(\"OpenAI API version: {}\".format(openai.api_version))\n",
    "print(\"OpenAI API type: {}\".format(openai.api_type))\n",
    "\n",
    "# Model endpoint names\n",
    "gpt35_model = os.getenv(\"OPENAI_GPT35_MODEL\")\n",
    "gpt35_16k_model = os.getenv(\"OPENAI_GPT35_16K_MODEL\")\n",
    "gpt4_model = os.getenv(\"OPENAI_GPT4_MODEL\")\n",
    "print(\"GPT-3.5-Turbo model: {}\".format(gpt35_model))\n",
    "print(\"GPT-3.5-Turbo-16k model: {}\".format(gpt35_16k_model))\n",
    "print(\"GPT-4 model: {}\".format(gpt4_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4.- Clase para creación de embeddings (vectores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(5))\n",
    "def generate_embeddings(text):\n",
    "    response = openai.Embedding.create(input=text, engine=embedding_model)\n",
    "    embeddings = response[\"data\"][0]['embedding']\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.- Clase de interfaz con modelos GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(3))\n",
    "def generate_text(prompt, model=gpt4_model, messages=[], max_tokens=600, temperature=0.5, top_p=1.0, frequency_penalty=0.0, presence_penalty=0.0, stop=None):\n",
    "    _messages = []\n",
    "    _messages.extend(messages)\n",
    "    _messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    \n",
    "    print(\"\\n\\n============================ PROMPT ============================\\n\")\n",
    "    for message in _messages:\n",
    "        print(f\"{message['role']}: {message['content']}\")\n",
    "        \n",
    "    response = openai.ChatCompletion.create(\n",
    "        engine=model,\n",
    "        messages=_messages,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        frequency_penalty=frequency_penalty,\n",
    "        presence_penalty=presence_penalty,\n",
    "        stop=stop\n",
    "    )\n",
    "    print(\"\\n\\n============================ RESPONSE ============================\\n\")\n",
    "    print(response[\"choices\"][0][\"message\"][\"content\"])\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_solution(instructions, problems):\n",
    "    instructions_str = \"\\n\".join([f\"text:\\n{i['prompt']}\\nscore:\\n{i['score']}\" for i in instructions])\n",
    "    \n",
    "    problems_str = \"\\n\".join([f\"Q:\\n{i['question']}\\nA:<INS>\\nGround Truth Answer:\\n{i['ground_truth']}\" for i in problems])\n",
    "    \n",
    "    prompt = f\"Your task is to generate the instruction <INS>. Below are some previous instructions with their scores. The score ranges from 0 to 100.\\n\\n{instructions_str}\\n\\nBelow are some problems.\\n{problems_str}\\n\\nGenerate an instruction that is different from all the instructions <INS> above, and has a higher score than all the instructions <INS> above. The instruction should begin with <INS> and end with </INS>. The instruction should be concise, effective, and generally applicable to all problems above.\"\n",
    "    \n",
    "    solution = generate_text(prompt, model=gpt4_model, temperature=1)\n",
    "    solution = solution.replace(\"<INS>\", \"\").replace(\"</INS>\", \"\")\n",
    "    return solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_answer(answer, question, ground_truth):\n",
    "    prompt = f\"Q:\\n{question}\\nA:\\n{answer}\\nGround Truth Answer:\\n{ground_truth}\\n\\nBased on the question, the answer and the ground truth answer: Give a score from 0 to 100 to the answer, where 0 means the answer is completely wrong, and 100 means the answer is completely correct.\\nScore:\"\n",
    "    score = generate_text(prompt, model=gpt4_model, temperature=0.2)\n",
    "    return int(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_solution(solution, problems):\n",
    "    scores = []\n",
    "    for problem in problems:\n",
    "        prompt = f\"Q:{problem['question']}\\nA:{solution}\"\n",
    "        answer = generate_text(prompt, model=gpt35_model, temperature=0.7)\n",
    "        score = evaluate_answer(answer, problem['question'], problem['ground_truth'])\n",
    "        scores.append(score)\n",
    "    \n",
    "    # return the average score\n",
    "    return sum(scores) / len(scores)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = [\n",
    "    {\n",
    "        \"prompt\": \"Let’s figure it out!\",\n",
    "        \"score\": 61\n",
    "    },\n",
    "    {\n",
    "        \"prompt\": \"Let’s solve the problem.\",\n",
    "        \"score\": 63\n",
    "    }\n",
    "]\n",
    "\n",
    "problems = [\n",
    "    {\n",
    "        \"question\": \"Alannah, Beatrix, and Queen are preparing for the new school year and have been given books by their parents. Alannah has 20 more books than Beatrix. Queen has 1/5 times more books than Alannah. If Beatrix has 30 books, how many books do the three have together?\",\n",
    "        \"ground_truth\": 140\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ITERATIONS = 3\n",
    "\n",
    "for i in range(MAX_ITERATIONS):\n",
    "    solution = generate_solution(instructions, problems)\n",
    "    score = test_solution(solution, problems)\n",
    "    instructions.append({\"prompt\": solution, \"score\": score})\n",
    "    \n",
    "# use tabulate to print the results\n",
    "print(tabulate(instructions, headers=\"keys\"))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
